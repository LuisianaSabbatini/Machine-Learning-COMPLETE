## Comprehensive Python Pandas Presentation
Slide 1: Introduction to Python Pandas

Pandas is a powerful Python library for data manipulation and analysis. It provides data structures like DataFrames and Series, which allow efficient handling of structured data. Pandas is built on top of NumPy and integrates well with other scientific computing libraries in Python.

Slide 2: Source Code for Introduction to Python Pandas

```python
import pandas as pd
import numpy as np

# Create a DataFrame
df = pd.DataFrame({
    'A': [1, 2, 3],
    'B': ['a', 'b', 'c'],
    'C': [4.5, 5.5, 6.5]
})

# Display the DataFrame
print(df)

# Basic information about the DataFrame
print(df.info())

# Summary statistics
print(df.describe())
```

Slide 3: Series in Pandas

A Series is a one-dimensional labeled array that can hold data of any type. It is similar to a column in a spreadsheet or a single column of a DataFrame. Series are the building blocks of DataFrames and are useful for handling time-series data or representing a single column of structured data.

Slide 4: Source Code for Series in Pandas

```python
import pandas as pd

# Create a Series from a list
s = pd.Series([1, 3, 5, 7, 9], index=['a', 'b', 'c', 'd', 'e'])

print("Series:")
print(s)

# Accessing elements
print("\nElement at index 'c':", s['c'])

# Series operations
print("\nSeries multiplied by 2:")
print(s * 2)

# Series statistics
print("\nMean of the Series:", s.mean())
print("Median of the Series:", s.median())
```

Slide 5: DataFrame Creation and Basic Operations

DataFrames are two-dimensional labeled data structures with columns of potentially different types. They are the primary data structure in Pandas and can be thought of as a table or a spreadsheet-like structure. DataFrames can be created from various data sources and support a wide range of operations for data manipulation.

Slide 6: Source Code for DataFrame Creation and Basic Operations

```python
import pandas as pd

# Create a DataFrame from a dictionary
data = {
    'Name': ['Alice', 'Bob', 'Charlie'],
    'Age': [25, 30, 35],
    'City': ['New York', 'San Francisco', 'Los Angeles']
}
df = pd.DataFrame(data)

print("DataFrame:")
print(df)

# Accessing columns
print("\nAge column:")
print(df['Age'])

# Adding a new column
df['Salary'] = [50000, 60000, 70000]
print("\nDataFrame with new column:")
print(df)

# Basic statistics
print("\nMean age:", df['Age'].mean())
print("Max salary:", df['Salary'].max())
```

Slide 7: Data Selection and Indexing

Pandas provides powerful tools for selecting and indexing data in DataFrames. You can select data based on labels, positions, or boolean conditions. Understanding these methods is crucial for efficient data manipulation and analysis.

Slide 8: Source Code for Data Selection and Indexing

```python
import pandas as pd

# Create a sample DataFrame
df = pd.DataFrame({
    'A': range(1, 6),
    'B': range(10, 15),
    'C': ['a', 'b', 'c', 'd', 'e']
})

print("Original DataFrame:")
print(df)

# Select a single column
print("\nColumn A:")
print(df['A'])

# Select multiple columns
print("\nColumns A and C:")
print(df[['A', 'C']])

# Select rows by label (index)
print("\nRow with index 2:")
print(df.loc[2])

# Select rows by position
print("\nFirst 3 rows:")
print(df.iloc[:3])

# Boolean indexing
print("\nRows where A > 3:")
print(df[df['A'] > 3])
```

Slide 9: Data Cleaning and Preprocessing

Data cleaning and preprocessing are essential steps in any data analysis project. Pandas offers various methods to handle missing values, remove duplicates, and transform data. These operations help ensure that your data is accurate and ready for analysis.

Slide 10: Source Code for Data Cleaning and Preprocessing

```python
import pandas as pd
import numpy as np

# Create a DataFrame with missing values and duplicates
df = pd.DataFrame({
    'A': [1, 2, np.nan, 4, 5, 5],
    'B': [5, 6, 7, np.nan, 9, 9],
    'C': ['a', 'b', 'c', 'd', 'e', 'e']
})

print("Original DataFrame:")
print(df)

# Handle missing values
df_filled = df.fillna(df.mean())
print("\nDataFrame with filled missing values:")
print(df_filled)

# Remove duplicates
df_unique = df.drop_duplicates()
print("\nDataFrame with duplicates removed:")
print(df_unique)

# Transform data
df['A_squared'] = df['A'] ** 2
print("\nDataFrame with new transformed column:")
print(df)
```

Slide 11: Grouping and Aggregation

Grouping and aggregation are powerful techniques for analyzing data by categories. Pandas' GroupBy functionality allows you to split data into groups, apply functions to each group, and combine the results. This is particularly useful for calculating summary statistics and performing complex data transformations.

Slide 12: Source Code for Grouping and Aggregation

```python
import pandas as pd

# Create a sample DataFrame
df = pd.DataFrame({
    'Category': ['A', 'B', 'A', 'B', 'A', 'C'],
    'Value1': [10, 20, 30, 40, 50, 60],
    'Value2': [100, 200, 300, 400, 500, 600]
})

print("Original DataFrame:")
print(df)

# Group by Category and calculate mean
grouped_mean = df.groupby('Category').mean()
print("\nMean values by Category:")
print(grouped_mean)

# Group by Category and apply multiple aggregations
grouped_agg = df.groupby('Category').agg({
    'Value1': ['sum', 'mean', 'max'],
    'Value2': ['min', 'median']
})
print("\nMultiple aggregations by Category:")
print(grouped_agg)
```

Slide 13: Merging and Joining DataFrames

Merging and joining are essential operations when working with multiple related datasets. Pandas provides various methods to combine DataFrames based on common columns or indices. Understanding these operations is crucial for integrating data from different sources and performing comprehensive analyses.

Slide 14: Source Code for Merging and Joining DataFrames

```python
import pandas as pd

# Create two sample DataFrames
df1 = pd.DataFrame({
    'ID': [1, 2, 3, 4],
    'Name': ['Alice', 'Bob', 'Charlie', 'David']
})

df2 = pd.DataFrame({
    'ID': [1, 2, 3, 5],
    'Age': [25, 30, 35, 40]
})

print("DataFrame 1:")
print(df1)
print("\nDataFrame 2:")
print(df2)

# Inner join
inner_join = pd.merge(df1, df2, on='ID', how='inner')
print("\nInner Join:")
print(inner_join)

# Left join
left_join = pd.merge(df1, df2, on='ID', how='left')
print("\nLeft Join:")
print(left_join)

# Outer join
outer_join = pd.merge(df1, df2, on='ID', how='outer')
print("\nOuter Join:")
print(outer_join)
```

Slide 15: Real-Life Example: Analyzing Weather Data

In this example, we'll analyze weather data to find the average temperature and total precipitation for each month. This demonstrates the practical application of Pandas in processing and analyzing real-world datasets.

Slide 16: Source Code for Analyzing Weather Data

```python
import pandas as pd
import numpy as np

# Create a sample weather dataset
dates = pd.date_range(start='2023-01-01', end='2023-12-31')
weather_data = pd.DataFrame({
    'Date': dates,
    'Temperature': np.random.normal(15, 5, len(dates)),
    'Precipitation': np.random.exponential(2, len(dates))
})

# Set the Date column as the index
weather_data.set_index('Date', inplace=True)

print("Sample of weather data:")
print(weather_data.head())

# Calculate monthly average temperature and total precipitation
monthly_stats = weather_data.resample('M').agg({
    'Temperature': 'mean',
    'Precipitation': 'sum'
})

print("\nMonthly weather statistics:")
print(monthly_stats)

# Find the hottest and wettest months
hottest_month = monthly_stats['Temperature'].idxmax()
wettest_month = monthly_stats['Precipitation'].idxmax()

print(f"\nHottest month: {hottest_month.strftime('%B')} with average temperature {monthly_stats.loc[hottest_month, 'Temperature']:.2f}Â°C")
print(f"Wettest month: {wettest_month.strftime('%B')} with total precipitation {monthly_stats.loc[wettest_month, 'Precipitation']:.2f} mm")
```

Slide 17: Real-Life Example: Analyzing Student Performance

In this example, we'll analyze student performance data to calculate average scores by subject and identify top-performing students. This demonstrates how Pandas can be used in educational data analysis.

Slide 18: Source Code for Analyzing Student Performance

```python
import pandas as pd
import numpy as np

# Create a sample student performance dataset
np.random.seed(42)
students = ['Student_' + str(i) for i in range(1, 51)]
subjects = ['Math', 'Science', 'English', 'History']

data = {
    'Student': np.repeat(students, len(subjects)),
    'Subject': subjects * len(students),
    'Score': np.random.randint(60, 100, len(students) * len(subjects))
}

df = pd.DataFrame(data)

print("Sample of student performance data:")
print(df.head(10))

# Calculate average scores by subject
subject_averages = df.groupby('Subject')['Score'].mean().sort_values(ascending=False)
print("\nAverage scores by subject:")
print(subject_averages)

# Identify top 5 students based on overall average
student_averages = df.groupby('Student')['Score'].mean().sort_values(ascending=False)
top_students = student_averages.head(5)
print("\nTop 5 students based on overall average:")
print(top_students)

# Find the highest score for each subject
highest_scores = df.groupby('Subject')['Score'].max()
print("\nHighest scores for each subject:")
print(highest_scores)
```

Slide 19: Additional Resources

For more advanced topics and in-depth understanding of Pandas, consider exploring the following resources:

1.  Official Pandas Documentation: [https://pandas.pydata.org/docs/](https://pandas.pydata.org/docs/)
2.  "Python for Data Analysis" by Wes McKinney (creator of Pandas)
3.  DataCamp's Pandas Tutorials: [https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python](https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python)
4.  Real Python's Pandas Tutorials: [https://realpython.com/learning-paths/pandas-data-science/](https://realpython.com/learning-paths/pandas-data-science/)

For academic papers related to data analysis and Pandas, you can search on ArXiv.org. Here's a relevant paper:

"Pandas: Powerful Python Data Analysis Toolkit" by Wes McKinney ArXiv URL: [https://arxiv.org/abs/2001.02140](https://arxiv.org/abs/2001.02140)

Remember to verify the accuracy and relevance of these resources, as they may have been updated since my last training data.

